{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    },
    "colab": {
      "name": "assignment 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_ZqlYlfdKng"
      },
      "source": [
        "Fatemeh Amanian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdU-CaI6dKnh"
      },
      "source": [
        "•Create three random tensors, including a 3 * 3 tensor as float, a 4 * 4 tensor as double, and a 5 * 3 * 4 tensor as short type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "dyAvux4SdKni",
        "outputId": "fe2bdb56-29eb-4e16-b451-d6b2d50f2450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "print(\"Imported!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imported!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCIK4k1LdKnm"
      },
      "source": [
        "•Change their elements in the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "UEaGckDSdKnm",
        "outputId": "89095aac-a26c-4914-b52e-92ea09e39f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "a = torch.rand(3, 3, dtype=torch.float)\n",
        "b = torch.rand(4, 4, dtype=torch.double)\n",
        "c = torch.randint(10, (5, 3, 4), dtype=torch.short)\n",
        "\n",
        "\n",
        "print(\" a: \\n\", a)\n",
        "print(\"\\n b: \\n\", b)\n",
        "print(\"\\n c: \\n\", c)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " a: \n",
            " tensor([[0.2846, 0.2663, 0.0358],\n",
            "        [0.3134, 0.6986, 0.7027],\n",
            "        [0.1764, 0.0387, 0.8290]])\n",
            "\n",
            " b: \n",
            " tensor([[0.5932, 0.8423, 0.6633, 0.6152],\n",
            "        [0.6251, 0.2348, 0.0880, 0.2586],\n",
            "        [0.7575, 0.6982, 0.2299, 0.3420],\n",
            "        [0.6454, 0.5159, 0.8085, 0.3504]], dtype=torch.float64)\n",
            "\n",
            " c: \n",
            " tensor([[[0, 0, 2, 1],\n",
            "         [3, 3, 4, 3],\n",
            "         [3, 6, 4, 4]],\n",
            "\n",
            "        [[8, 0, 5, 6],\n",
            "         [1, 8, 6, 0],\n",
            "         [3, 8, 5, 3]],\n",
            "\n",
            "        [[4, 6, 2, 1],\n",
            "         [0, 6, 0, 6],\n",
            "         [2, 6, 9, 9]],\n",
            "\n",
            "        [[0, 9, 4, 6],\n",
            "         [2, 4, 0, 4],\n",
            "         [0, 0, 0, 5]],\n",
            "\n",
            "        [[6, 3, 6, 7],\n",
            "         [4, 6, 9, 4],\n",
            "         [8, 6, 3, 4]]], dtype=torch.int16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMBZV_UndKnp",
        "outputId": "793d0c20-d7c8-4b4a-867e-b1525a476b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# First create gpu tensor:\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# torch.cuda.FloatTensor(1000, 1000).fill_(0)\n",
        "# with torch.cuda.device(1):\n",
        "#     a_gpu = torch.randn(3, 3, dtype=torch.float).cuda(device)\n",
        "#     b_gpu = torch.randn(4, 4, dtype=torch.double).cuda(device)\n",
        "#     c_gpu = torch.randn(10, (5, 3, 4), dtype=torch.short).cuda(device)\n",
        "a_gpu = torch.cuda.FloatTensor(3, 3).random_()\n",
        "b_gpu = torch.cuda.DoubleTensor(4, 4).random_()\n",
        "c_gpu = torch.cuda.ShortTensor(5, 3, 4).random_()\n",
        "\n",
        "print(\" a_gpu:\", a_gpu)\n",
        "print(\"\\n b_gpu:\", b_gpu)\n",
        "print(\"\\n c_gpu:\", c_gpu)\n",
        "# Then we change the cells:\n",
        "a_gpu[1,2] = 0.0\n",
        "b_gpu[1,:] = torch.tensor([0, 0, 0, 0])\n",
        "c_gpu[0,:,:] =  torch.tensor(\n",
        "    [\n",
        "        [0, 0, 0, 0],\n",
        "        [0, 0, 0, 0],\n",
        "        [0, 0, 0, 0]\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"\\n a_gpu:\", a_gpu)\n",
        "print(\"\\n b_gpu:\", b_gpu)\n",
        "print(\"\\n c_gpu:\", c_gpu)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " a_gpu: tensor([[ 1289892.,   232549.,    80542.],\n",
            "        [13043976.,   287579., 13220967.],\n",
            "        [15400037.,  8167349., 11062332.]], device='cuda:0')\n",
            "\n",
            " b_gpu: tensor([[3.1191e+15, 4.3581e+15, 4.8495e+15, 5.1102e+15],\n",
            "        [3.0040e+15, 3.8618e+15, 6.1918e+14, 6.6076e+15],\n",
            "        [1.8738e+15, 5.5065e+15, 4.8425e+15, 6.8001e+14],\n",
            "        [4.7670e+15, 4.5914e+15, 5.6427e+15, 5.0657e+15]], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "\n",
            " c_gpu: tensor([[[ 6364, 19959, 15365,   151],\n",
            "         [16504,  2572,  4011,  7065],\n",
            "         [21224, 10916,  9239, 30882]],\n",
            "\n",
            "        [[19493, 12948, 26103, 14130],\n",
            "         [  549, 27773, 23080, 10071],\n",
            "         [19562, 30507, 26454, 10740]],\n",
            "\n",
            "        [[21378,  8487, 21772, 20214],\n",
            "         [17496, 14153, 29462, 13989],\n",
            "         [ 2145, 19889,  3658, 10241]],\n",
            "\n",
            "        [[  880,  7130, 11780,  7254],\n",
            "         [29357, 27814,  6015,  4651],\n",
            "         [21811, 32655, 32332,  9647]],\n",
            "\n",
            "        [[ 2572, 10919, 17792, 31354],\n",
            "         [19424, 19080, 14491, 18108],\n",
            "         [11587, 28104, 13564, 17973]]], device='cuda:0', dtype=torch.int16)\n",
            "\n",
            " a_gpu: tensor([[ 1289892.,   232549.,    80542.],\n",
            "        [13043976.,   287579.,        0.],\n",
            "        [15400037.,  8167349., 11062332.]], device='cuda:0')\n",
            "\n",
            " b_gpu: tensor([[3.1191e+15, 4.3581e+15, 4.8495e+15, 5.1102e+15],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.8738e+15, 5.5065e+15, 4.8425e+15, 6.8001e+14],\n",
            "        [4.7670e+15, 4.5914e+15, 5.6427e+15, 5.0657e+15]], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "\n",
            " c_gpu: tensor([[[    0,     0,     0,     0],\n",
            "         [    0,     0,     0,     0],\n",
            "         [    0,     0,     0,     0]],\n",
            "\n",
            "        [[19493, 12948, 26103, 14130],\n",
            "         [  549, 27773, 23080, 10071],\n",
            "         [19562, 30507, 26454, 10740]],\n",
            "\n",
            "        [[21378,  8487, 21772, 20214],\n",
            "         [17496, 14153, 29462, 13989],\n",
            "         [ 2145, 19889,  3658, 10241]],\n",
            "\n",
            "        [[  880,  7130, 11780,  7254],\n",
            "         [29357, 27814,  6015,  4651],\n",
            "         [21811, 32655, 32332,  9647]],\n",
            "\n",
            "        [[ 2572, 10919, 17792, 31354],\n",
            "         [19424, 19080, 14491, 18108],\n",
            "         [11587, 28104, 13564, 17973]]], device='cuda:0', dtype=torch.int16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXUKAO2KdKns"
      },
      "source": [
        " •Display the order of its elements and its transpose in the memory then use storage offset and contiguous:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ZEtg1ijpdKns",
        "outputId": "fdff0ac9-352e-4317-af1c-7e07889a1917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Display the order of its elements:\n",
        "d = torch.randint(10, (4, 4), dtype=torch.short)\n",
        "d[0,:] = torch.tensor([-1, -1, -1, -1])\n",
        "\n",
        "print(\" d: \\n\" , d)\n",
        "d_t = d.transpose(0,1)\n",
        "print(\"\\n d transposed: \\n\", d_t)\n",
        "\n",
        "print(\" d in memory: \\n\" , d.storage())\n",
        "d_t = d.transpose(0,1)\n",
        "print(\"\\n d transposed in the memory: \\n\", d_t.storage())\n",
        "\n",
        "# See wether it's contiguous or not:\n",
        "print(\"\\n Is d contiguous?: \", d.is_contiguous())\n",
        "print(\"\\n Is d transposed contiguous?: \", d_t.is_contiguous())\n",
        "\n",
        "# Make it contiguous:\n",
        "d_t_contig = d_t.contiguous()\n",
        "\n",
        "print(\"\\n Make d_t contiguous: \\n\")\n",
        "print(\"\\n d_t_contig: \\n\", d_t_contig)\n",
        "print(\"\\n d_t_contig in memory: \\n\", d_t_contig.storage())\n",
        "\n",
        "\n",
        "# Cut the tensor:\n",
        "d_cut = d[1,:]\n",
        "print(\"\\n d cutted: \\n\", d_cut)\n",
        "print(\"\\n d cutted in memory: \\n\", d_cut.storage())\n",
        "print(\"\\n d cutted offset: \\n\", d_cut.storage_offset())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " d: \n",
            " tensor([[-1, -1, -1, -1],\n",
            "        [ 1,  1,  2,  9],\n",
            "        [ 9,  2,  6,  3],\n",
            "        [ 5,  2,  4,  1]], dtype=torch.int16)\n",
            "\n",
            " d transposed: \n",
            " tensor([[-1,  1,  9,  5],\n",
            "        [-1,  1,  2,  2],\n",
            "        [-1,  2,  6,  4],\n",
            "        [-1,  9,  3,  1]], dtype=torch.int16)\n",
            " d in memory: \n",
            "  -1\n",
            " -1\n",
            " -1\n",
            " -1\n",
            " 1\n",
            " 1\n",
            " 2\n",
            " 9\n",
            " 9\n",
            " 2\n",
            " 6\n",
            " 3\n",
            " 5\n",
            " 2\n",
            " 4\n",
            " 1\n",
            "[torch.ShortStorage of size 16]\n",
            "\n",
            " d transposed in the memory: \n",
            "  -1\n",
            " -1\n",
            " -1\n",
            " -1\n",
            " 1\n",
            " 1\n",
            " 2\n",
            " 9\n",
            " 9\n",
            " 2\n",
            " 6\n",
            " 3\n",
            " 5\n",
            " 2\n",
            " 4\n",
            " 1\n",
            "[torch.ShortStorage of size 16]\n",
            "\n",
            " Is d contiguous?:  True\n",
            "\n",
            " Is d transposed contiguous?:  False\n",
            "\n",
            " Make d_t contiguous: \n",
            "\n",
            "\n",
            " d_t_contig: \n",
            " tensor([[-1,  1,  9,  5],\n",
            "        [-1,  1,  2,  2],\n",
            "        [-1,  2,  6,  4],\n",
            "        [-1,  9,  3,  1]], dtype=torch.int16)\n",
            "\n",
            " d_t_contig in memory: \n",
            "  -1\n",
            " 1\n",
            " 9\n",
            " 5\n",
            " -1\n",
            " 1\n",
            " 2\n",
            " 2\n",
            " -1\n",
            " 2\n",
            " 6\n",
            " 4\n",
            " -1\n",
            " 9\n",
            " 3\n",
            " 1\n",
            "[torch.ShortStorage of size 16]\n",
            "\n",
            " d cutted: \n",
            " tensor([1, 1, 2, 9], dtype=torch.int16)\n",
            "\n",
            " d cutted in memory: \n",
            "  -1\n",
            " -1\n",
            " -1\n",
            " -1\n",
            " 1\n",
            " 1\n",
            " 2\n",
            " 9\n",
            " 9\n",
            " 2\n",
            " 6\n",
            " 3\n",
            " 5\n",
            " 2\n",
            " 4\n",
            " 1\n",
            "[torch.ShortStorage of size 16]\n",
            "\n",
            " d cutted offset: \n",
            " 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBnyrk3BdKnv"
      },
      "source": [
        "•Save and load one among the elements of tensors using the torch and the h5py file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_-VZsWkdKnw",
        "outputId": "d6ac1175-30aa-4b06-ff1b-0d293b9e2085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "import h5py\n",
        " \n",
        "# Saving:\n",
        "f = h5py.File('file.h5', 'w')\n",
        "f.create_dataset('data', data=c)\n",
        "f.close()\n",
        "# Loading:\n",
        "f = h5py.File('file.h5','r')\n",
        "c_new = f['data'][:]\n",
        "f.close()\n",
        " \n",
        "print(\"\\n tensor c after loading: \\n\", c_new)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor c after loading: \n",
            " [[[0 0 2 1]\n",
            "  [3 3 4 3]\n",
            "  [3 6 4 4]]\n",
            "\n",
            " [[8 0 5 6]\n",
            "  [1 8 6 0]\n",
            "  [3 8 5 3]]\n",
            "\n",
            " [[4 6 2 1]\n",
            "  [0 6 0 6]\n",
            "  [2 6 9 9]]\n",
            "\n",
            " [[0 9 4 6]\n",
            "  [2 4 0 4]\n",
            "  [0 0 0 5]]\n",
            "\n",
            " [[6 3 6 7]\n",
            "  [4 6 9 4]\n",
            "  [8 6 3 4]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDD6NL76dKnz"
      },
      "source": [
        "•Show the different true and false requires_grad values in Autograd by the backward method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "qqtoaWVjdKnz",
        "outputId": "8423d608-5d72-4370-feec-e7f80924b339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "\n",
        "# Autograd: autograd is a tool to take differentiation and\n",
        "#  calculating gradients of tensors inside the neural model.\n",
        "\n",
        "# Create a simple graph model:\n",
        "# x = torch.rand(2, 2, dtype=torch.float)\n",
        "x = torch.tensor(\n",
        "    [\n",
        "        [1.0, 2.0],\n",
        "        [3.0, 4.0]\n",
        "    ]\n",
        ")\n",
        "print(\"\\n x: \\n\", x)\n",
        "\n",
        "# Track the tensor x so its gradient could be calculated later:\n",
        "x.requires_grad = True\n",
        "\n",
        "# y = torch.rand(2, 2, dtype=torch.float)\n",
        "y = torch.tensor(\n",
        "    [\n",
        "        [5.0, 6.0],\n",
        "        [7.0, 8.0]\n",
        "    ]\n",
        ")\n",
        "print(\"\\n y: \\n\", y)\n",
        "\n",
        "# Define a function:\n",
        "z = x * y + x\n",
        "print(\"\\n z = x * y + x: \\n\", z)\n",
        "\n",
        "# Do a backpropagation:\n",
        "# (gives an error if no tensor has set its requires_grad attribute to False)\n",
        "z = z.sum()\n",
        "z.backward()\n",
        "\n",
        "print(\"\\n gradient of dz/dx (should be y + 1): \\n\", x.grad)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " x: \n",
            " tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "\n",
            " y: \n",
            " tensor([[5., 6.],\n",
            "        [7., 8.]])\n",
            "\n",
            " z = x * y + x: \n",
            " tensor([[ 6., 14.],\n",
            "        [24., 36.]], grad_fn=<AddBackward0>)\n",
            "\n",
            " gradient of dz/dx (should be y + 1): \n",
            " tensor([[6., 7.],\n",
            "        [8., 9.]])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}